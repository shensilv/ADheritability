{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3bd6c5c-73d6-40d4-84ca-6e7fe6595275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import dxpy\n",
    "import dxdata\n",
    "import pandas as pd\n",
    "\n",
    "# Spark initialization (Done only once; do not rerun this cell unless you select Kernel -> Restart kernel).\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "\n",
    "# Automatically discover dispensed database name and dataset id\n",
    "dispensed_database = dxpy.find_one_data_object(\n",
    "    classname=\"database\", \n",
    "    name=\"app*\", \n",
    "    folder=\"/\", \n",
    "    name_mode=\"glob\", \n",
    "    describe=True)\n",
    "dispensed_database_name = dispensed_database[\"describe\"][\"name\"]\n",
    "\n",
    "dispensed_dataset = dxpy.find_one_data_object(\n",
    "    typename=\"Dataset\", \n",
    "    name=\"app*.dataset\", \n",
    "    folder=\"/\", \n",
    "    name_mode=\"glob\")\n",
    "dispensed_dataset_id = dispensed_dataset[\"id\"]\n",
    "\n",
    "dataset = dxdata.load_dataset(id=dispensed_dataset_id)\n",
    "participant = dataset[\"participant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d88dd13-d278-4024-9002-08e4c710aedc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------------+-----------------+---------+---------+---------+---------+---------+---------+----------+---------+---------+----------+\n",
      "|eid    |p31   |p22000       |p54_i0           |p22009_a1|p22009_a2|p22009_a3|p22009_a4|p22009_a5|p22009_a6|p22009_a7 |p22009_a8|p22009_a9|p22009_a10|\n",
      "+-------+------+-------------+-----------------+---------+---------+---------+---------+---------+---------+----------+---------+---------+----------+\n",
      "|5970576|Female|UKBiLEVEAX_b2|Leeds            |-12.6693 |4.30928  |-2.23438 |-0.109226|-7.364   |-1.01024 |1.31101   |-1.4512  |3.99414  |-1.68128  |\n",
      "|4620207|Male  |null         |Stockport (pilot)|null     |null     |null     |null     |null     |null     |null      |null     |null     |null      |\n",
      "|3544231|Male  |Batch_b004   |Glasgow          |-13.7558 |5.64773  |-3.58187 |7.74165  |21.0285  |0.711038 |-0.0382205|0.162054 |1.54023  |-0.545929 |\n",
      "|3308524|Female|Batch_b055   |Sheffield        |-12.3794 |2.03865  |-0.837131|-0.562303|2.60283  |-1.36413 |2.78978   |-2.11815 |0.0113227|-0.155375 |\n",
      "|1106345|Female|Batch_b007   |Liverpool        |-12.6667 |4.18819  |-1.96996 |2.85875  |0.6597   |0.795101 |2.07537   |-0.8787  |-2.67951 |2.85529   |\n",
      "+-------+------+-------------+-----------------+---------+---------+---------+---------+---------+---------+----------+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fields = ['eid', 'p31', 'p22000', 'p54_i0', 'p22009_a1', 'p22009_a2', 'p22009_a3', 'p22009_a4', 'p22009_a5', 'p22009_a6', 'p22009_a7', 'p22009_a8', 'p22009_a9', 'p22009_a10']\n",
    "df = participant.retrieve_fields(names=fields, engine=dxdata.connect(), coding_values=\"replace\")\n",
    "# Show the first 5 lines of the spark dataframe\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395724a5-bb33-460d-b4f2-7e5ddd109c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in 50k eids\n",
    "eids_100k = pd.read_csv(\"eids_keep_100k.csv\", header=None) \n",
    "eids_100k.columns = ['eid']\n",
    "# eids_50k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a083ed-abcb-42a4-8f5e-2117bead1307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/spark/python/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+---------+---------+---------+---------+---------+---------+---------+----------+---------+---------+----------+\n",
      "|eid    |p31   |p22000    |p54_i0   |p22009_a1|p22009_a2|p22009_a3|p22009_a4|p22009_a5|p22009_a6|p22009_a7 |p22009_a8|p22009_a9|p22009_a10|\n",
      "+-------+------+----------+---------+---------+---------+---------+---------+---------+---------+----------+---------+---------+----------+\n",
      "|3544231|Male  |Batch_b004|Glasgow  |-13.7558 |5.64773  |-3.58187 |7.74165  |21.0285  |0.711038 |-0.0382205|0.162054 |1.54023  |-0.545929 |\n",
      "|1106345|Female|Batch_b007|Liverpool|-12.6667 |4.18819  |-1.96996 |2.85875  |0.6597   |0.795101 |2.07537   |-0.8787  |-2.67951 |2.85529   |\n",
      "|1458523|Female|Batch_b093|Glasgow  |-13.3813 |3.63312  |-3.34136 |9.06684  |17.796   |-1.28133 |0.80981   |0.550325 |1.7284   |1.5269    |\n",
      "|4018308|Female|Batch_b004|Edinburgh|-14.3743 |2.25444  |-2.81493 |7.63346  |13.5495  |2.33539  |-1.21718  |0.611471 |0.644174 |0.375372  |\n",
      "|1438109|Female|Batch_b052|Newcastle|-10.8751 |2.70764  |-3.02955 |3.19403  |2.22136  |0.899907 |1.72315   |0.0636943|1.26472  |-1.63274  |\n",
      "+-------+------+----------+---------+---------+---------+---------+---------+---------+---------+----------+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In order to filter the spark dataframe using a pandas dataframe, we need to broadcast the pandas df and then join\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "eids_100k_spark = spark.createDataFrame(eids_100k)\n",
    "eids_100k_broadcasted = broadcast(eids_100k_spark)\n",
    "covars_100k = df.join(eids_100k_broadcasted, on=\"eid\", how=\"inner\")\n",
    "covars_100k.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb89cae-b096-4d21-b343-11b144a3f352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91466\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(covars_100k.count()) # check number of rows - 48262\n",
    "print(len(covars_100k.columns)) # check number of columns, should be eid + sex + array + centre + 10 PCs = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcd4cfe2-1f4e-48be-972d-f8a8d741cd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "covars_100k_pd = covars_100k.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d962656-14e6-4429-a2b8-be9aa9d55d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#First, convert batch to either 'Affymetrix' or 'Illumina', and sex into 'F' or 'M'\n",
    "covars_100k_pd['batch'] = covars_100k_pd['p22000'].apply(lambda x: 'Affymetrix' if x.startswith('UKBiLEVE') else ('Illumina' if x.startswith('Batch') else None))\n",
    "covars_100k_pd['sex'] = covars_100k_pd['p31'].apply(lambda x: 'F' if x == 'Female' else 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992ff742-94a9-4e05-9557-084425a8b9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Next, we need to separate continuous and discrete covars. \n",
    "\n",
    "discrete_pd = covars_100k_pd[['eid', 'eid', 'batch', 'sex', 'p54_i0']]\n",
    "cont_pd = covars_100k_pd[['eid', 'eid', 'p22009_a1', 'p22009_a2', 'p22009_a3', 'p22009_a4','p22009_a5','p22009_a6','p22009_a7','p22009_a8','p22009_a9','p22009_a10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b22ccf66-e0e2-47d1-9d62-44281d20eb5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discrete_pd.to_csv('discrete_covars_100k.tsv', header=False, sep='\\t', index=False)\n",
    "cont_pd.to_csv('cont_covars_100k.tsv', header=False, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3707937f-dd78-42b6-a1bb-aba2365a1543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                file-GqJK1Q8Jg5yP0Zz500g7gY79\n",
      "Class                             file\n",
      "Project                           project-GbfkzqQJg5y0KGvVy2ByF23b\n",
      "Folder                            /\n",
      "Name                              discrete_covars_100k.tsv\n",
      "State                             closing\n",
      "Visibility                        visible\n",
      "Types                             -\n",
      "Properties                        -\n",
      "Tags                              -\n",
      "Outgoing links                    -\n",
      "Created                           Fri Sep  6 11:00:17 2024\n",
      "Created by                        s_shen\n",
      " via the job                      job-GqJJj4QJg5y5XgJ89f5JKv5F\n",
      "Last modified                     Fri Sep  6 11:00:18 2024\n",
      "Media type                        \n",
      "archivalState                     \"live\"\n",
      "cloudAccount                      \"cloudaccount-dnanexus\"\n",
      "ID                                file-GqJK1QQJg5yF78kQxGYByXBX\n",
      "Class                             file\n",
      "Project                           project-GbfkzqQJg5y0KGvVy2ByF23b\n",
      "Folder                            /\n",
      "Name                              cont_covars_100k.tsv\n",
      "State                             closing\n",
      "Visibility                        visible\n",
      "Types                             -\n",
      "Properties                        -\n",
      "Tags                              -\n",
      "Outgoing links                    -\n",
      "Created                           Fri Sep  6 11:00:18 2024\n",
      "Created by                        s_shen\n",
      " via the job                      job-GqJJj4QJg5y5XgJ89f5JKv5F\n",
      "Last modified                     Fri Sep  6 11:00:19 2024\n",
      "Media type                        \n",
      "archivalState                     \"live\"\n",
      "cloudAccount                      \"cloudaccount-dnanexus\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "dx upload discrete_covars_100k.tsv --dest /\n",
    "dx upload cont_covars_100k.tsv --dest /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b9b02e-e02e-4d9b-91c6-21a7c8bfc6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
